{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thought Process Here...\n",
    "\n",
    "My goal here was to do parameter recovery using an HMM.\n",
    "\n",
    "As a reminder, parameter recovery involves generating the parameters of a model using real-world data, then using our model to generate lots of simulated data. We then use that simulated data to estimate model parameters. If our simulated model parameters match our original 'real-world' model parameters, then we have successfully performed model recovery.\n",
    "\n",
    "My intention here was to do model recovery on the Li *et al.* data. However, I'm having a hard time loading their data in and making any meaningful sense of it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful references for this:\n",
    "\n",
    "- https://hmmlearn.readthedocs.io/en/latest/auto_examples/plot_variational_inference.html\n",
    "- https://hmmlearn.readthedocs.io/en/latest/auto_examples/plot_casino.html\n",
    "- https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a generative model with 2 hidden states: high suspense and low suspense\n",
    "gen_model = hmm.CategoricalHMM(n_components=2, random_state=99)\n",
    "# At the start of the round, they're in a low suspenses state\n",
    "gen_model.startprob_ = np.array([1.0, 0.0])\n",
    "# Let's initialise the transition probability matrix\n",
    "# Part of our experiment is to see if people are keen to reach states of high suspense, \n",
    "# so we could bear that in mind\n",
    "# we'll intialise with 25% chance of staying and 75% of transitioning higher\n",
    "gen_model.transmat_ = np.array([[0.25, 0.75], # Transition matrix describes the probabilities of transitioning between hidden states\n",
    "                               [0.8, 0.2]])\n",
    "# now we can intitialise the emissions matrix\n",
    "# these are the probs of being in each hidden state given the observation\n",
    "# in this initial case, say we observe 4 states: 1, 2, 3, 4 (in reality, we have like 21+ states remember)\n",
    "# We can imagine that 1 and 2 are low suspense, and 3 and 4 are high suspense\n",
    "gen_model.emissionprob_ = np.array([ # emission matrix describes the probabilities of being in each hidden state (rows) for each observation (cols)\n",
    "    [0.4, 0.3, 0.2, 0.1], # i.e. probability we're in low suspense condition given each observation\n",
    "    [0.1, 0.2, 0.3, 0.4] # probability we're in low suspense condition given each observation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls, gen_states = gen_model.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #0\tScore: -2079.2023916242306\n",
      "Model #1\tScore: -2085.7473541887784\n",
      "Model #2\tScore: -2076.5715494280234\n",
      "Model #3\tScore: -2081.0994465932536\n",
      "Model #4\tScore: -2079.1353917697265\n",
      "Model #5\tScore: -2074.358454441661\n",
      "Model #6\tScore: -2074.236949701335\n",
      "Model #7\tScore: -2071.8984451128363\n",
      "Model #8\tScore: -2080.968518959379\n",
      "Model #9\tScore: -2080.6361359573903\n",
      "Model #10\tScore: -2081.8742622767954\n",
      "Model #11\tScore: -2076.69108513878\n",
      "Model #12\tScore: -2084.6860628696963\n",
      "Model #13\tScore: -2080.373920441045\n",
      "Model #14\tScore: -2078.118810856695\n",
      "Model #15\tScore: -2081.0933643611447\n",
      "Model #16\tScore: -2080.0528072430097\n",
      "Model #17\tScore: -2079.8051915973524\n",
      "Model #18\tScore: -2078.305514372171\n",
      "Model #19\tScore: -2080.1039744034247\n",
      "Model #20\tScore: -2076.204594353516\n",
      "Model #21\tScore: -2078.0701733149967\n",
      "Model #22\tScore: -2079.4196688870416\n",
      "Model #23\tScore: -2078.9957554343227\n",
      "Model #24\tScore: -2072.616659093793\n",
      "Model #25\tScore: -2075.338893905001\n",
      "Model #26\tScore: -2079.955695350764\n",
      "Model #27\tScore: -2078.212939456073\n",
      "Model #28\tScore: -2080.051581419177\n",
      "Model #29\tScore: -2073.374084638906\n",
      "Model #30\tScore: -2080.057506289375\n",
      "Model #31\tScore: -2081.190213307808\n",
      "Model #32\tScore: -2082.1191135482964\n",
      "Model #33\tScore: -2087.845784985504\n",
      "Model #34\tScore: -2082.941131144541\n",
      "Model #35\tScore: -2082.118715906665\n",
      "Model #36\tScore: -2077.2873330448\n",
      "Model #37\tScore: -2080.4566191835547\n",
      "Model #38\tScore: -2080.4976037917445\n",
      "Model #39\tScore: -2078.5571994046454\n",
      "Model #40\tScore: -2077.7957459913882\n",
      "Model #41\tScore: -2081.38855853642\n",
      "Model #42\tScore: -2079.9427278507924\n",
      "Model #43\tScore: -2081.933158360461\n",
      "Model #44\tScore: -2080.8846002336736\n",
      "Model #45\tScore: -2075.4557379471835\n",
      "Model #46\tScore: -2081.7277501984395\n",
      "Model #47\tScore: -2074.474995547887\n",
      "Model #48\tScore: -2075.2947952031127\n",
      "Model #49\tScore: -2079.5191997863094\n",
      "Generated score: -2072.2922297440637\n",
      "Best score: -2071.8984451128363\n"
     ]
    }
   ],
   "source": [
    "# Do parameter recovery on our initial model\n",
    "\n",
    "# Split data into training and validation\n",
    "x_train = rolls[:rolls.shape[0] // 2]\n",
    "x_validate = rolls[rolls.shape[0] // 2:]\n",
    "\n",
    "# Generate an initial optimal score\n",
    "gen_score = gen_model.score(x_validate)\n",
    "best_score = best_model = None\n",
    "\n",
    "n_fits = 50\n",
    "np.random.seed(13)\n",
    "for ix in range(n_fits):\n",
    "    model = hmm.CategoricalHMM(\n",
    "        n_components=2, n_features=4, random_state=ix, init_params='ste'\n",
    "    )\n",
    "    model.fit(x_train)\n",
    "    score = model.score(x_validate)\n",
    "    print(f'Model #{ix}\\tScore: {score}')\n",
    "    if best_score is None or score > best_score:\n",
    "        best_model = model\n",
    "        best_score = score\n",
    "\n",
    "print(f'Generated score: {gen_score}\\nBest score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = best_model.predict(rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Matrix Generated:\n",
      "[[0.25 0.75]\n",
      " [0.8  0.2 ]]\n",
      "\n",
      "Transmission Matrix Recovered:\n",
      "[[0.187 0.813]\n",
      " [0.636 0.364]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Transmission Matrix Generated:\\n{gen_model.transmat_.round(3)}\\n\\n'\n",
    "      f'Transmission Matrix Recovered:\\n{best_model.transmat_.round(3)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rolls = np.array([[0, 0, 1, 1, 2, 2, 3]])\n",
    "best_model.predict(test_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build out HMM that learns the transition and emission probabilities from a data generation process.\n",
    "\n",
    "Here we use 10 components, where a component is an observational state. As our observation, we'll use the difference between the upper bound and the current cumulative score.\n",
    "\n",
    "There are 5 possible suspense categories.\n",
    "\n",
    "We'll start with a simple deck of cards made up of [1, 2, 3, 4, 5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = hmm.CategoricalHMM(n_components=5, random_state=99)\n",
    "# Define the initial state, which will be P(no suspense) = 1.0\n",
    "gen_model.startprob_ = np.array([1.0, 0.0, 0.0, 0.0, 0.0])\n",
    "# Initialise transition probabilities - i.e. transitions between hidden states\n",
    "gen_model.transmat_ = np.array([\n",
    "    [0.1, 0.2, 0.2, 0.2, 0.3],\n",
    "    [0.1, 0.2, 0.2, 0.2, 0.3],\n",
    "    [0.1, 0.2, 0.2, 0.2, 0.3],\n",
    "    [0.1, 0.2, 0.2, 0.2, 0.3],\n",
    "    [0.1, 0.2, 0.2, 0.2, 0.3],\n",
    "]) # Setting to uniform probabilities\n",
    "# Initialise emission probabilities\n",
    "# But as we previously said, observations aren't just the single card we draw, but the 2 cards per draw and our cumulative sum\n",
    "gen_model.emissionprob_ = np.array([\n",
    "    [], # If I'm in suspense state 1, then these are the probabilities of being in each observable state\n",
    "    [], # If I'm in suspense state 2, ...\n",
    "    [], # If I'm in suspense state 3, ...\n",
    "    [], # If I'm in suspense state 4, ...\n",
    "    [], # If I'm in suspense state 5, ...\n",
    "])\n",
    "\n",
    "# I think there's something here we could do where we use the Ely model to fill out the emission probabilities, \n",
    "# but I'm not sure why or how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.dirichlet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "emissionprob_ rows must sum to 1 (got row sums of [20 20 20 20 20])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rolls, gen_states \u001b[38;5;241m=\u001b[39m \u001b[43mgen_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agrog\\Documents\\UCL\\Project\\Code\\expecting-suspense\\.venv\\lib\\site-packages\\hmmlearn\\_emissions.py:27\u001b[0m, in \u001b[0;36m_make_wrapper.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_wrapper\u001b[39m(func):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mwraps(func)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\agrog\\Documents\\UCL\\Project\\Code\\expecting-suspense\\.venv\\lib\\site-packages\\hmmlearn\\base.py:428\u001b[0m, in \u001b[0;36m_AbstractHMM.sample\u001b[1;34m(self, n_samples, random_state, currstate)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03mGenerate random samples from the model.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    X, Z = model.sample(n_samples=10, currstate=Z[-1])\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    427\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n",
      "File \u001b[1;32mc:\\Users\\agrog\\Documents\\UCL\\Project\\Code\\expecting-suspense\\.venv\\lib\\site-packages\\hmmlearn\\hmm.py:148\u001b[0m, in \u001b[0;36mCategoricalHMM._check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memissionprob_ must have shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_sum_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memissionprob_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agrog\\Documents\\UCL\\Project\\Code\\expecting-suspense\\.venv\\lib\\site-packages\\hmmlearn\\base.py:951\u001b[0m, in \u001b[0;36mBaseHMM._check_sum_1\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    949\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(s, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must sum to 1 (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows must sum to 1 (got row sums of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    956\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: emissionprob_ rows must sum to 1 (got row sums of [20 20 20 20 20])"
     ]
    }
   ],
   "source": [
    "rolls, gen_states = gen_model.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4],\n",
       "        [0],\n",
       "        [5],\n",
       "        ...,\n",
       "        [7],\n",
       "        [2],\n",
       "        [9]], dtype=int64),\n",
       " array([0, 4, 4, ..., 2, 1, 0]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls, gen_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #0\tScore: -5759.794395951346\n",
      "Model #1\tScore: -5771.450658093483\n",
      "Model #2\tScore: -5765.021981520111\n",
      "Model #3\tScore: -5766.8158882599255\n",
      "Model #4\tScore: -5762.734601296893\n",
      "Model #5\tScore: -5759.905162126905\n",
      "Model #6\tScore: -5768.268424751389\n",
      "Model #7\tScore: -5760.90241431093\n",
      "Model #8\tScore: -5767.463672924933\n",
      "Model #9\tScore: -5764.193729068568\n",
      "Model #10\tScore: -5768.161153955828\n",
      "Model #11\tScore: -5774.522961011975\n",
      "Model #12\tScore: -5767.777258875839\n",
      "Model #13\tScore: -5762.003227996799\n",
      "Model #14\tScore: -5773.049015994076\n",
      "Model #15\tScore: -5766.999935855021\n",
      "Model #16\tScore: -5764.46306415079\n",
      "Model #17\tScore: -5758.692333916654\n",
      "Model #18\tScore: -5763.914937322704\n",
      "Model #19\tScore: -5761.477299642822\n",
      "Model #20\tScore: -5773.778972990429\n",
      "Model #21\tScore: -5762.12018562717\n",
      "Model #22\tScore: -5764.46267851638\n",
      "Model #23\tScore: -5762.355782255059\n",
      "Model #24\tScore: -5762.166076045307\n",
      "Model #25\tScore: -5765.850250387814\n",
      "Model #26\tScore: -5766.094441356654\n",
      "Model #27\tScore: -5779.692454713297\n",
      "Model #28\tScore: -5766.709568329386\n",
      "Model #29\tScore: -5767.009043128394\n",
      "Model #30\tScore: -5775.815366477672\n",
      "Model #31\tScore: -5764.701871114693\n",
      "Model #32\tScore: -5761.224663304687\n",
      "Model #33\tScore: -5771.3620563789345\n",
      "Model #34\tScore: -5767.093472343882\n",
      "Model #35\tScore: -5767.523475359669\n",
      "Model #36\tScore: -5766.937656015295\n",
      "Model #37\tScore: -5769.551798671942\n",
      "Model #38\tScore: -5768.946187199169\n",
      "Model #39\tScore: -5763.270791469375\n",
      "Model #40\tScore: -5772.49368328515\n",
      "Model #41\tScore: -5765.498723448425\n",
      "Model #42\tScore: -5768.930546788033\n",
      "Model #43\tScore: -5762.379784907546\n",
      "Model #44\tScore: -5765.983675514301\n",
      "Model #45\tScore: -5781.703500606765\n",
      "Model #46\tScore: -5781.324688883583\n",
      "Model #47\tScore: -5766.066728368158\n",
      "Model #48\tScore: -5763.4807026999715\n",
      "Model #49\tScore: -5768.165970470627\n",
      "Generated score: -5756.462732485286\n",
      "Best score: -5758.692333916654\n"
     ]
    }
   ],
   "source": [
    "# Do parameter recovery on our initial model\n",
    "\n",
    "# Split data into training and validation\n",
    "x_train = rolls[:rolls.shape[0] // 2]\n",
    "x_validate = rolls[rolls.shape[0] // 2:]\n",
    "\n",
    "# Generate an initial optimal score\n",
    "gen_score = gen_model.score(x_validate)\n",
    "best_score = best_model = None\n",
    "\n",
    "n_fits = 50\n",
    "np.random.seed(13)\n",
    "for ix in range(n_fits):\n",
    "    model = hmm.CategoricalHMM(\n",
    "        n_components=5, n_features=10, random_state=ix, init_params='ste'\n",
    "    )\n",
    "    model.fit(x_train)\n",
    "    score = model.score(x_validate)\n",
    "    print(f'Model #{ix}\\tScore: {score}')\n",
    "    if best_score is None or score > best_score:\n",
    "        best_model = model\n",
    "        best_score = score\n",
    "\n",
    "print(f'Generated score: {gen_score}\\nBest score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = best_model.predict(rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission Matrix Generated:\n",
      "[[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]]\n",
      "\n",
      "Transmission Matrix Recovered:\n",
      "[[0.926 0.056 0.    0.014 0.004]\n",
      " [0.1   0.041 0.049 0.001 0.809]\n",
      " [0.001 0.045 0.034 0.032 0.888]\n",
      " [0.361 0.498 0.119 0.006 0.015]\n",
      " [0.001 0.    0.196 0.002 0.801]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Transmission Matrix Generated:\\n{gen_model.transmat_.round(3)}\\n\\n'\n",
    "      f'Transmission Matrix Recovered:\\n{best_model.transmat_.round(3)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
